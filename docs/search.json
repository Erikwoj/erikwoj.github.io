[
  {
    "objectID": "basic-example.html",
    "href": "basic-example.html",
    "title": "Erik Wojcik",
    "section": "",
    "text": "I am Business Administration Major with a Minor in Data Analytics at The State University of New York at Geneseo. I am interested in helping others through my knowledge in Finance and Wealth Management."
  },
  {
    "objectID": "basic-example.html#education",
    "href": "basic-example.html#education",
    "title": "Erik Wojcik",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo| Geneseo, New York | 2023 - Bachelor of Science in Business Administration - Data Analytics"
  },
  {
    "objectID": "basic-example.html#professional-experience",
    "href": "basic-example.html#professional-experience",
    "title": "Erik Wojcik",
    "section": "Professional Experience",
    "text": "Professional Experience\nM&T Bank / Wilmington Trust | Buffalo, New York | Summer 2023 - Incoming Management Development Program Trainee (Wealth Management)\nState University of New York at Geneseo | Geneseo, New York | 2022-Present - Financial Aid Office Assistant (Work Study Program)\nState University of New York at Geneseo | Geneseo, New York | 2022-Present - Finance and Data Analytics Research Assistant\nRich Products | Buffalo, New York | 2021-2022 - Business Analytics Intern"
  },
  {
    "objectID": "DANL310_hw1_Wojcik_Erik.html",
    "href": "DANL310_hw1_Wojcik_Erik.html",
    "title": "Homework 1",
    "section": "",
    "text": "Renovate your personal website on GitHub using Quarto.\n✔️\n\n\n\nProvide ggplot codes to replicate the given figure.\n\nncdc_temp <- read_csv(\n  'https://bcdanl.github.io/data/ncdc_temp_cleaned.csv')\nlibrary(lubridate)\nggplot(ncdc_temp, aes(x = date, y = temperature, color = location)) +\n\ngeom_line(size = 1) + # Adds a layer to the ggplot object with a line plot of the temperature data, with a size of 1.\n\nscale_x_date(name = \"month\", limits = c(ymd(\"0000-01-01\"), ymd(\"0001-01-04\")), # Adds a scale to the x-axis with the label \"month\" and limits of Jan 1, 0000 to Jan 4, 0001, and breaks at the beginning of each quarter (Jan, Apr, Jul, Oct), with corresponding labels.\nbreaks = c(ymd(\"0000-01-01\"), ymd(\"0000-04-01\"), ymd(\"0000-07-01\"),\nymd(\"0000-10-01\"), ymd(\"0001-01-01\")),\nlabels = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\", \"Jan\"), expand = c(1/366, 0)) +\n\nscale_y_continuous(limits = c(19.9, 107), # Adds a scale to the y-axis with limits of 19.9 to 107, breaks at every 20 units, and label \"temperature (°F)\".\nbreaks = seq(20, 100, by = 20),\nname = \"temperature (°F)\") +\n\ntheme(legend.title.align = 0.5) # Adjusts the alignment of the legend title to be centered.\n\n\n\n\n\n\n\n\nncdc_temp <- read_csv(\n  'https://bcdanl.github.io/data/ncdc_temp_cleaned.csv')\nlibrary('ggplot2')\np <- ggplot(ncdc_temp, aes(x = month, y = temperature)) \n\n  # add a box plot with grey fill\np + geom_boxplot(fill = 'grey90') + \n  # add labels for x and y axes\n  labs(x = \"month\",\n       y = \"mean temperature (°F)\") \n\n\n\np\n\n\n\n\n\n\n\n\nncdc_temp <- read_csv(\n  'https://bcdanl.github.io/data/ncdc_temp_cleaned.csv')\n\nggridges::geom_density_ridges()\n\ngeom_density_ridges: na.rm = FALSE, panel_scaling = TRUE\nstat_density_ridges: na.rm = FALSE\nposition_points_sina \n\np <- ggplot(ncdc_temp, aes(x = temperature, y = month)) \n\np + ggridges::geom_density_ridges( # Adds a layer to the ggplot object with a smoothed density plot of the temperature data using the 'ridgeline' plot type.\n  scale = 3, rel_min_height = 0.01, # Sets the scaling and minimum relative height for the plot.\n  bandwidth = 3.4, fill = \"#56B4E9\", color = \"white\" # Sets the bandwidth for the plot, as well as the fill and color for the plot elements.\n) +\n\nscale_x_continuous( # Adds a scale to the x-axis for continuous values.\n  name = \"mean temperature (°F)\", # Sets the label for the x-axis.\n  expand = c(0, 0), breaks = c(0, 25, 50, 75) # Sets the expansion and the break points for the x-axis.\n) +\n\nscale_y_discrete(\n  name = \"month\", expand = c(0, .2, 0, 2.6)) + # Adds a scale to the y-axis for discrete (categorical) values, with a label and a custom expansion.\n\ntheme( # Applies a custom theme to the ggplot object.\n  plot.margin = margin(3, 7, 3, 1.5) # Sets the margin of the plot.\n)\n\n\n\n\n\n\n\n\nm <- ggplot(data = mtcars, aes(x = disp, y = mpg, color = hp)) \n\nm + geom_point(aes(color = hp)) + # add scatter plot with color mapped to \"hp\" variable\n  labs(x = \"displacement(cu. in.)\", y = \"fuel efficiency(mpg)\")+ # add labels to x and y axes\n  scale_color_gradient()+ # add color gradient scale legend\n  scale_fill_brewer(palette = \"Emrld\") # add fill color palette with \"Emrld\" scheme to the legend\n\n\n\n\n\n\n\n\npopgrowth_df <- read_csv(\n  'https://bcdanl.github.io/data/popgrowth.csv')\np <- ggplot(popgrowth_df, \n            aes(x = reorder(state, popgrowth), \n                y = 100*popgrowth, \n                fill = region))\np + geom_col() + # Add the geom for the columns\n  scale_y_continuous(\n    limits = c(-.6, 37.5), expand = c(0, 0), # Set y axis limits and expansion\n    labels = scales::percent_format(accuracy = 1, scale = 1), # Set percent labels for y axis\n    name = \"population growth, 2000 to 2010\" # Set name for y axis\n    ) +\n  coord_flip() + # Flip the x and y axis\n  theme(legend.position = c(.67, .4), # Set legend position\n        axis.text.y = element_text( size = 6, \n                                    margin = margin(t = 0, r = 0, b = 0, l = 0) )) # Adjust the size and margin for y axis text\n\n\n\n\n\n\n\n\nmale_Aus <- read_csv(\n  'https://bcdanl.github.io/data/aus_athletics_male.csv')\n\n# Define color and fill vectors for use in plot\ncolors <- c(\"#BD3828\", rep(\"#808080\", 4))\nfills <- c(\"#BD3828D0\", rep(\"#80808080\", 4))\n\np <- ggplot(male_Aus, aes(x=height, y=pcBfat, shape=sport, color = sport, fill = sport))\n\n# Add geom_point layer with custom size\np + geom_point(size = 3) +\n\n# Set shape values for different sports\n  scale_shape_manual(values = 21:25) +\n\n# Set color values for different sports\n  scale_color_manual(values = colors) +\n\n# Set fill values for different sports\n  scale_fill_manual(values = fills) +\n\n# Set x and y axis labels\n  labs(x = \"height (cm)\",\n       y = \"% body fat\" )\n\n\n\n\n\n\n\n\ntitanic <- read_csv(\n  'https://bcdanl.github.io/data/titanic_cleaned.csv')\n\np <- ggplot(titanic, aes(x = age, y = after_stat(count) ) ) \n\n# Add a density line plot for all passengers with transparent color, and fill legend with \"all passengers\"\np + geom_density(\n    data = select(titanic, -sex), \n    aes(fill = \"all passengers\"),\n    color = \"transparent\"\n  ) + \n  # Add another density line plot for each sex with transparent color, and fill legend with sex\n  geom_density(aes(fill = sex), bw = 2, color = \"transparent\") +\n  # Set the x-axis limits, name, and expand arguments\n  scale_x_continuous(limits = c(0, 75), name = \"passenger age (years)\", expand = c(0, 0)) +\n  # Set the y-axis limits, name, and expand arguments\n  scale_y_continuous(limits = c(0, 26), name = \"count\", expand = c(0, 0)) +\n  # Set the manual color and fill values, breaks, and labels for the legend\n  scale_fill_manual(\n    values = c(\"#b3b3b3a0\", \"#0072B2\", \"#D55E00\"), \n    breaks = c(\"all passengers\", \"male\", \"female\"),\n    labels = c(\"all passengers  \", \"males  \", \"females\"),\n    name = NULL,\n    guide = guide_legend(direction = \"horizontal\")\n  ) +\n  # Set the Cartesian coordinate system to allow for data points to fall outside the plot limits\n  coord_cartesian(clip = \"off\") +\n  # Create separate density line plots for male and female passengers\n  facet_wrap(~sex) +\n  # Set the x-axis line to blank, increase the strip text size, and set the legend position and margin\n  theme(\n    axis.line.x = element_blank(),\n    strip.text = element_text(size = 14, margin = margin(0, 0, 0.2, 0, \"cm\")),\n    legend.position = \"bottom\",\n    legend.justification = \"right\",\n    legend.margin = margin(4.5, 0, 1.5, 0, \"pt\"),\n    legend.spacing.x = grid::unit(4.5, \"pt\"),\n    legend.spacing.y = grid::unit(0, \"pt\"),\n    legend.box.spacing = grid::unit(0, \"cm\")\n  )\n\n\n\n\n\n\n\n\ncows_filtered <- read_csv(\n  'https://bcdanl.github.io/data/cows_filtered.csv')\n\n\np <- ggplot(cows_filtered, aes(x = butterfat, color = breed, fill = breed))\n\n# add a density line for each breed with some transparency\np + geom_density(alpha = .2) +\n\n# set x-axis properties\nscale_x_continuous(\n  expand = c(0, 0), # remove padding from axis limits\n  labels = scales::percent_format(accuracy = 1, scale = 1), # format axis labels as percentages with 1 decimal point\n  name = \"butterfat contents\" # set axis label\n) +\n\n# set y-axis properties\nscale_y_continuous(limits = c(0, 1.99), expand = c(0, 0)) +\n\n# set plot area properties\ncoord_cartesian(clip = \"off\") + # allow density lines to extend beyond axis limits\ntheme(axis.line.x = element_blank()) # remove x-axis line"
  },
  {
    "objectID": "Erik's_Website.html",
    "href": "Erik's_Website.html",
    "title": "Erik Wojcik",
    "section": "",
    "text": "I am a student at State University of New York at Geneseo.\nI am interested in Finance and Wealth Management."
  },
  {
    "objectID": "Erik's_Website.html#education",
    "href": "Erik's_Website.html#education",
    "title": "Erik Wojcik",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo, 2023 - Bachelor of Science in Business Administration - Data Analytics"
  },
  {
    "objectID": "Erik's_Website.html#professional-experience",
    "href": "Erik's_Website.html#professional-experience",
    "title": "Erik Wojcik",
    "section": "Professional Experience",
    "text": "Professional Experience\nM&T Bank / Wilmington Trust, 2023 - Incoming Management Development Program Trainee (Wealth Management)\nState University of New York at Geneseo, 2022-2023 - Financial Aid Office Assistant (Work Study Program)\nState University of New York at Geneseo, 2022-2023 - Finance and Data Analytics Research Assistant\nRich Products, 2021-2022 - Business Analytics Intern"
  },
  {
    "objectID": "hw0.html",
    "href": "hw0.html",
    "title": "Homework 1",
    "section": "",
    "text": "Renovate your personal website on GitHub using Quarto."
  },
  {
    "objectID": "teamproj0.html",
    "href": "teamproj0.html",
    "title": "Comparing Apple (AAPL) & S&P 500 (SPY) Using Capital Asset Pricing Model",
    "section": "",
    "text": "1 Project Proposal\nProposal for DANL 310 Project by Erik Wojcik, majoring in Business Administration with a minor in Data Analytics.\nApple Inc. is one of the most prominent companies in the world with a market capitalization of over $2 trillion. Apple’s stock price is often used as an indicator of the health of the tech industry and the stock market as a whole. The S&P 500 is a benchmark index of 500 of the largest publicly traded companies in the United States. By comparing Apple’s performance to the S&P 500 through a Capital Asset Pricing Model (CAPM), I can gain insights into the relative performance of Apple as an investment opportunity and how it has responded to different market conditions over the years. This project is interesting because it provides a deeper understanding of the performance of Apple, which can be useful for investors, financial analysts, and researchers.\nMy research question is “How does Apple’s stock price compare to the S&P 500 using a Capital Asset Pricing Model (CAPM) from 2000-2023?”\nThe data for this project will be obtained from a reputable financial data provider, such as Yahoo Finance or Google Finance. I will collect daily closing prices for Apple’s stock (AAPL) and the S&P 500 Index (SPY) from January 1, 2000, to March 28, 2023. This will provide a total of 6,023 daily observations for each security. I will also collect data on the risk-free rate of return (such as the yield on 10-year U.S. Treasury bonds) for each day in the sample period.\nSummary statistics and visualizations of the data will be used to gain insights into the performance of Apple’s stock and the S&P 500. I will examine the mean, standard deviation, minimum, maximum, and skewness of daily returns for each security. I will also create a scatter plot of Apple’s returns against the returns of the S&P 500 to visually compare their performance.\nThe modeling approach I will use is a Capital Asset Pricing Model (CAPM), which is widely used in finance to estimate the expected return on an investment. I will estimate the beta coefficient for Apple’s stock using a linear regression model with the S&P 500 Index returns as the independent variable and Apple’s returns as the dependent variable. I will also estimate the alpha coefficient, which measures the excess return of Apple’s stock compared to the expected return based on its beta coefficient and the risk-free rate.\nMy statistical hypothesis is that Apple’s stock has a positive beta coefficient, indicating that it is positively correlated with the overall market (as represented by the S&P 500). I also expect to find that Apple’s alpha coefficient is statistically significant, indicating that it has provided a higher return than expected based on its level of market risk.\nThe project will be divided into four main parts: data collection and cleaning, data exploration and visualization, modeling and analysis, and report writing. In the first phase, I will collect and clean the data, removing any missing or erroneous data points. In the second phase, I will explore the data through summary statistics and visualizations to gain insights into the performance of Apple and the S&P 500. In the third phase, I will estimate the beta and alpha coefficients using a linear regression model and interpret the results. Finally, in the fourth phase, I will write a report summarizing my findings, including insights into Apple’s performance, the statistical significance of my results, and potential implications for investors.\n\n\n2 Visualization (Not Complete)\n\n# Load necessary packages\nlibrary(tidyverse)\n\n# Load and clean data\napple <- read.csv(\"AAPL.csv\") %>%\n  filter(!is.na(Adj.Close)) %>%\n  select(Date, Adj.Close) %>%\n  rename(AAPL = Adj.Close)\n\nspy <- read.csv(\"SPY.csv\") %>%\n  filter(!is.na(Adj.Close)) %>%\n  select(Date, Adj.Close) %>%\n  rename(SPY = Adj.Close)\n\nrf_rate <- read.csv(\"RF.csv\") %>%\n  filter(!is.na(Adj.Close)) %>%\n  select(Date, Adj.Close) %>%\n  rename(RF = Adj.Close)\n\ndata <- left_join(left_join(apple, spy), rf_rate)\n\n\n\n\ndata <- data %>%\n  mutate(daily_return_aapl = AAPL/lag(AAPL) - 1,\n         daily_return_spy = SPY/lag(SPY) - 1)\n         ###mutate(daily_return_rf = RF/252))\n\n# Create scatterplot of returns\nggplot(data, aes(x = daily_return_spy, y = daily_return_aapl)) +\n  geom_point() +\n  labs(x = \"S&P 500 Returns\", y = \"AAPL Returns\") +\n  ggtitle(\"AAPL vs. S&P 500 Returns\")\n\n\n\n# Calculate beta and alpha coefficients\n\n###model <- lm(daily_return_aapl ~ daily_return_spy + daily_rf_rate, data = data)\n#summary(model)\n\n# Interpret results\n\n###beta <- coef(model)[\"daily_return_spy\"]\n###alpha <- coef(model)[\"(Intercept)\"]\n\n\n# load required packages\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# read data from CSV files\nAAPL <- read.csv(\"AAPL.csv\")\nSPY <- read.csv(\"SPY.csv\")\nRF <- read.csv(\"RF.csv\")\n\n# convert date columns to date format\nAAPL$Date <- as.Date(AAPL$Date)\nSPY$Date <- as.Date(SPY$Date)\nRF$Date <- as.Date(RF$Date)\n\n# merge data by date\n###data <- AAPL %>%\n  ###inner_join(SPY, by = \"Date\") %>%\n  ###inner_join(RF, by = \"Date\") %>%\n  ###mutate(daily_return_AAPL = (Adj.Close.x/lag(Adj.Close.x, 1)) - 1,\n         ###daily_return_SPY = (Adj.Close.y/lag(Adj.Close.y, 1))-1,\n         #daily_rf_rate = RF/252)\n\n\n# plot daily returns of AAPL and SPY over time\n###ggplot(data, aes(x = Date)) +\n  ###geom_line(aes(y = daily_return_AAPL, color = \"AAPL\")) +\n  ###geom_line(aes(y = daily_return_SPY, color = \"SPY\")) +\n  ###labs(title = \"Daily Returns of AAPL and SPY\",\n      ###x = \"Date\", y = \"Daily Return\",\n       ###color = \"Security\") +\n  ###scale_color_manual(values = c(\"red\", \"blue\")) +\n  ###theme_minimal()"
  },
  {
    "objectID": "teamproj0.html#capital-asset-pricing-model-using-linear-regression",
    "href": "teamproj0.html#capital-asset-pricing-model-using-linear-regression",
    "title": "Erik Wojcik: S&P 500’s Capital Asset Pricing Model Using Linear Regression",
    "section": "1 Capital Asset Pricing Model Using Linear Regression",
    "text": "1 Capital Asset Pricing Model Using Linear Regression\n  XXX\n\ncc_belief_county <- read_csv(\n  'https://bcdanl.github.io/data/cc_belief_county.csv'\n)\n\n\nlegend_title <- \"\"\n\nggplot(data = cc_belief_county) +\n  geom_polygon(aes(long, lat, group = group, \n                   fill = human2018),\n               color = \"grey\", size = 0.1) +\n  coord_map(\"bonne\", parameters = 41.6) + \n  scale_fill_gradient(legend_title, \n                      low='#0057e7', \n                      high='#d62d20') +\n  theme_map() + \n  theme(legend.position=\"right\") +\n  labs(caption = \"Data source: Yale Climate Change Communication\")"
  },
  {
    "objectID": "teamproj0.html#proposal-for-individual-project",
    "href": "teamproj0.html#proposal-for-individual-project",
    "title": "Comparing Apple (AAPL) & S&P 500 (SPY) Using Capital Asset Pricing Model",
    "section": "1 Proposal For Individual Project",
    "text": "1 Proposal For Individual Project"
  },
  {
    "objectID": "teamproj0.html#my-project-proposal",
    "href": "teamproj0.html#my-project-proposal",
    "title": "My Project",
    "section": "1.1 My Project Proposal",
    "text": "1.1 My Project Proposal"
  },
  {
    "objectID": "DANL310_hw2_Wojcik_Erik.html",
    "href": "DANL310_hw2_Wojcik_Erik.html",
    "title": "Homework 2",
    "section": "",
    "text": "Proposal for DANL 310 Project by Erik Wojcik, majoring in Business Administration with a minor in Data Analytics.\nApple Inc. is one of the most prominent companies in the world with a market capitalization of over $2 trillion. Apple’s stock price is often used as an indicator of the health of the tech industry and the stock market as a whole. The S&P 500 is a benchmark index of 500 of the largest publicly traded companies in the United States. By comparing Apple’s performance to the S&P 500 through a Capital Asset Pricing Model (CAPM), I can gain insights into the relative performance of Apple as an investment opportunity and how it has responded to different market conditions over the years. This project is interesting because it provides a deeper understanding of the performance of Apple, which can be useful for investors, financial analysts, and researchers.\nMy research question is “How does Apple’s stock price compare to the S&P 500 using a Capital Asset Pricing Model (CAPM) from 2000-2023?”\nThe data for this project will be obtained from a reputable financial data provider, such as Yahoo Finance or Google Finance. I will collect daily closing prices for Apple’s stock (AAPL) and the S&P 500 Index (SPY) from January 1, 2000, to March 28, 2023. This will provide a total of 6,023 daily observations for each security. I will also collect data on the risk-free rate of return (such as the yield on 10-year U.S. Treasury bonds) for each day in the sample period.\nSummary statistics and visualizations of the data will be used to gain insights into the performance of Apple’s stock and the S&P 500. I will examine the mean, standard deviation, minimum, maximum, and skewness of daily returns for each security. I will also create a scatter plot of Apple’s returns against the returns of the S&P 500 to visually compare their performance.\nThe modeling approach I will use is a Capital Asset Pricing Model (CAPM), which is widely used in finance to estimate the expected return on an investment. I will estimate the beta coefficient for Apple’s stock using a linear regression model with the S&P 500 Index returns as the independent variable and Apple’s returns as the dependent variable. I will also estimate the alpha coefficient, which measures the excess return of Apple’s stock compared to the expected return based on its beta coefficient and the risk-free rate.\nMy statistical hypothesis is that Apple’s stock has a positive beta coefficient, indicating that it is positively correlated with the overall market (as represented by the S&P 500). I also expect to find that Apple’s alpha coefficient is statistically significant, indicating that it has provided a higher return than expected based on its level of market risk.\nThe project will be divided into four main parts: data collection and cleaning, data exploration and visualization, modeling and analysis, and report writing. In the first phase, I will collect and clean the data, removing any missing or erroneous data points. In the second phase, I will explore the data through summary statistics and visualizations to gain insights into the performance of Apple and the S&P 500. In the third phase, I will estimate the beta and alpha coefficients using a linear regression model and interpret the results. Finally, in the fourth phase, I will write a report summarizing my findings, including insights into Apple’s performance, the statistical significance of my results, and potential implications for investors.\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read in the CSV file\nhdi_corruption &lt;- read.csv('https://bcdanl.github.io/data/hdi_corruption.csv')\n\n# Create a vector of colors for each region\nregion_colors &lt;- c(\"Americas\" = \"#F9B8AA\", \n                   \"Asia Pacific\" = \"#D7E295\", \n                   \"Europe and Central Asia\" = \"#95E2B5\", \n                   \"Middle East and North Africa\" = \"#95E2E1\", \n                   \"Sub Saharan Africa\" = \"#E295DD\")\n\n# Create the scatter plot\np&lt;- ggplot(hdi_corruption, aes(x = cpi, y = hdi, color = region)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = region_colors) +\n  geom_smooth(se = FALSE,\n              method = \"loess\",\n              formula = y ~ x, color = \"blue\", size = 1) +\n  labs(title = \"Corruption Perception Index vs. Human Development Index by Region\",\n       x = \"Corruption Perception Index,2014 (100 = least corrupt)\",\n       y = \"Human Development Index, 20014 (1.0 = most developed)\",\n       color = \"Region\") +\n  theme_minimal()+\n  xlim(20, 80) +\n  ylim(0.4, 1.0) +\n  geom_text(data = hdi_corruption %&gt;% filter(country %in% c(\"Argentina\", \"China\", \"Egypt\", \"Greece\", \"South Africa\", \"Senegal\", \"United States\", \"Germany\", \"Norway\", \"Singapore\")),\n            aes(x = cpi, y = hdi, label = country), \n            size = 2, hjust = -0.2, vjust = -0.2, color = \"black\")\n\np+theme(aspect.ratio = 1)\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nlabor_supply &lt;- read.csv(\"labor_supply.csv\")\n\nlabor_subset &lt;- labor_supply %&gt;% \n  select(YEAR, SEX, NCHLT5, LABFORCE, ASECWT)\n\nlabor_subset$has_children &lt;- ifelse(labor_subset$NCHLT5 == 0, \"No\", \"Yes\")\n\nlabor_subset &lt;- labor_subset %&gt;% \n  filter(LABFORCE != 0)\n\npop_by_year_sex_children &lt;- labor_subset %&gt;% \n  group_by(YEAR, SEX, has_children) %&gt;% \n  summarize(labor_pop = sum(ASECWT[LABFORCE == 2]), civilian_pop = sum(ASECWT))\n\nlfp_by_year_sex_children &lt;- pop_by_year_sex_children %&gt;% \n  mutate(lfp_rate = labor_pop / civilian_pop)\n\nlfp_by_year_sex_children &lt;- lfp_by_year_sex_children %&gt;% \n  filter(!is.na(lfp_rate))\n\nlfp_by_year_sex_children$SEX &lt;- factor(lfp_by_year_sex_children$SEX, labels = c(\"Male\", \"Female\"))\n\nplot_no_children &lt;- ggplot(data = lfp_by_year_sex_children %&gt;% filter(has_children == \"No\"),\n                           aes(x = YEAR, y = lfp_rate, color = SEX, group = SEX)) +\n  geom_line() +\n  labs(title = \"Labor force participation rate by gender for households with no children under the age of 5\",\n       x = \"Year\",\n       y = \"Labor force participation rate\")\n\nplot_with_children &lt;- ggplot(data = lfp_by_year_sex_children %&gt;% filter(has_children == \"Yes\"),\n                             aes(x = YEAR, y = lfp_rate, color = SEX, group = SEX)) +\n  geom_line() +\n  labs(title = \"Labor force participation rate by gender for households with at least one child under the age of 5\",\n       x = \"Year\",\n       y = \"Labor force participation rate\")\n\nlibrary(gridExtra)\ngrid.arrange(plot_no_children, plot_with_children, ncol = 2)"
  },
  {
    "objectID": "DANL310_hw2_Wojcik_Erik.html#question-1",
    "href": "DANL310_hw2_Wojcik_Erik.html#question-1",
    "title": "Homework 2",
    "section": "",
    "text": "Proposal for DANL 310 Project by Erik Wojcik, majoring in Business Administration with a minor in Data Analytics.\nApple Inc. is one of the most prominent companies in the world with a market capitalization of over $2 trillion. Apple’s stock price is often used as an indicator of the health of the tech industry and the stock market as a whole. The S&P 500 is a benchmark index of 500 of the largest publicly traded companies in the United States. By comparing Apple’s performance to the S&P 500 through a Capital Asset Pricing Model (CAPM), I can gain insights into the relative performance of Apple as an investment opportunity and how it has responded to different market conditions over the years. This project is interesting because it provides a deeper understanding of the performance of Apple, which can be useful for investors, financial analysts, and researchers.\nMy research question is “How does Apple’s stock price compare to the S&P 500 using a Capital Asset Pricing Model (CAPM) from 2000-2023?”\nThe data for this project will be obtained from a reputable financial data provider, such as Yahoo Finance or Google Finance. I will collect daily closing prices for Apple’s stock (AAPL) and the S&P 500 Index (SPY) from January 1, 2000, to March 28, 2023. This will provide a total of 6,023 daily observations for each security. I will also collect data on the risk-free rate of return (such as the yield on 10-year U.S. Treasury bonds) for each day in the sample period.\nSummary statistics and visualizations of the data will be used to gain insights into the performance of Apple’s stock and the S&P 500. I will examine the mean, standard deviation, minimum, maximum, and skewness of daily returns for each security. I will also create a scatter plot of Apple’s returns against the returns of the S&P 500 to visually compare their performance.\nThe modeling approach I will use is a Capital Asset Pricing Model (CAPM), which is widely used in finance to estimate the expected return on an investment. I will estimate the beta coefficient for Apple’s stock using a linear regression model with the S&P 500 Index returns as the independent variable and Apple’s returns as the dependent variable. I will also estimate the alpha coefficient, which measures the excess return of Apple’s stock compared to the expected return based on its beta coefficient and the risk-free rate.\nMy statistical hypothesis is that Apple’s stock has a positive beta coefficient, indicating that it is positively correlated with the overall market (as represented by the S&P 500). I also expect to find that Apple’s alpha coefficient is statistically significant, indicating that it has provided a higher return than expected based on its level of market risk.\nThe project will be divided into four main parts: data collection and cleaning, data exploration and visualization, modeling and analysis, and report writing. In the first phase, I will collect and clean the data, removing any missing or erroneous data points. In the second phase, I will explore the data through summary statistics and visualizations to gain insights into the performance of Apple and the S&P 500. In the third phase, I will estimate the beta and alpha coefficients using a linear regression model and interpret the results. Finally, in the fourth phase, I will write a report summarizing my findings, including insights into Apple’s performance, the statistical significance of my results, and potential implications for investors."
  },
  {
    "objectID": "DANL310_hw2_Wojcik_Erik.html#question-2a",
    "href": "DANL310_hw2_Wojcik_Erik.html#question-2a",
    "title": "Homework 2",
    "section": "",
    "text": "library(ggplot2)\nlibrary(dplyr)\n\n# Read in the CSV file\nhdi_corruption &lt;- read.csv('https://bcdanl.github.io/data/hdi_corruption.csv')\n\n# Create a vector of colors for each region\nregion_colors &lt;- c(\"Americas\" = \"#F9B8AA\", \n                   \"Asia Pacific\" = \"#D7E295\", \n                   \"Europe and Central Asia\" = \"#95E2B5\", \n                   \"Middle East and North Africa\" = \"#95E2E1\", \n                   \"Sub Saharan Africa\" = \"#E295DD\")\n\n# Create the scatter plot\np&lt;- ggplot(hdi_corruption, aes(x = cpi, y = hdi, color = region)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = region_colors) +\n  geom_smooth(se = FALSE,\n              method = \"loess\",\n              formula = y ~ x, color = \"blue\", size = 1) +\n  labs(title = \"Corruption Perception Index vs. Human Development Index by Region\",\n       x = \"Corruption Perception Index,2014 (100 = least corrupt)\",\n       y = \"Human Development Index, 20014 (1.0 = most developed)\",\n       color = \"Region\") +\n  theme_minimal()+\n  xlim(20, 80) +\n  ylim(0.4, 1.0) +\n  geom_text(data = hdi_corruption %&gt;% filter(country %in% c(\"Argentina\", \"China\", \"Egypt\", \"Greece\", \"South Africa\", \"Senegal\", \"United States\", \"Germany\", \"Norway\", \"Singapore\")),\n            aes(x = cpi, y = hdi, label = country), \n            size = 2, hjust = -0.2, vjust = -0.2, color = \"black\")\n\np+theme(aspect.ratio = 1)"
  },
  {
    "objectID": "DANL310_hw2_Wojcik_Erik.html#question-2b",
    "href": "DANL310_hw2_Wojcik_Erik.html#question-2b",
    "title": "Homework 2",
    "section": "",
    "text": "library(tidyverse)\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nlabor_supply &lt;- read.csv(\"labor_supply.csv\")\n\nlabor_subset &lt;- labor_supply %&gt;% \n  select(YEAR, SEX, NCHLT5, LABFORCE, ASECWT)\n\nlabor_subset$has_children &lt;- ifelse(labor_subset$NCHLT5 == 0, \"No\", \"Yes\")\n\nlabor_subset &lt;- labor_subset %&gt;% \n  filter(LABFORCE != 0)\n\npop_by_year_sex_children &lt;- labor_subset %&gt;% \n  group_by(YEAR, SEX, has_children) %&gt;% \n  summarize(labor_pop = sum(ASECWT[LABFORCE == 2]), civilian_pop = sum(ASECWT))\n\nlfp_by_year_sex_children &lt;- pop_by_year_sex_children %&gt;% \n  mutate(lfp_rate = labor_pop / civilian_pop)\n\nlfp_by_year_sex_children &lt;- lfp_by_year_sex_children %&gt;% \n  filter(!is.na(lfp_rate))\n\nlfp_by_year_sex_children$SEX &lt;- factor(lfp_by_year_sex_children$SEX, labels = c(\"Male\", \"Female\"))\n\nplot_no_children &lt;- ggplot(data = lfp_by_year_sex_children %&gt;% filter(has_children == \"No\"),\n                           aes(x = YEAR, y = lfp_rate, color = SEX, group = SEX)) +\n  geom_line() +\n  labs(title = \"Labor force participation rate by gender for households with no children under the age of 5\",\n       x = \"Year\",\n       y = \"Labor force participation rate\")\n\nplot_with_children &lt;- ggplot(data = lfp_by_year_sex_children %&gt;% filter(has_children == \"Yes\"),\n                             aes(x = YEAR, y = lfp_rate, color = SEX, group = SEX)) +\n  geom_line() +\n  labs(title = \"Labor force participation rate by gender for households with at least one child under the age of 5\",\n       x = \"Year\",\n       y = \"Labor force participation rate\")\n\nlibrary(gridExtra)\ngrid.arrange(plot_no_children, plot_with_children, ncol = 2)"
  }
]